{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import PIL\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from sky_segmentation.modules.networks import SkySegmentationModel\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "from mit_semseg.utils import colorEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = scipy.io.loadmat('../artifacts/data/metadata/color150.mat')['colors']\n",
    "names = {}\n",
    "with open('../artifacts/data/metadata/object150_info.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        names[int(row[0])] = row[5].split(\";\")[0]\n",
    "\n",
    "def visualize_result(img, pred, index=None):\n",
    "    # filter prediction class if requested\n",
    "    if index is not None:\n",
    "        pred = pred.copy()\n",
    "        pred[pred != index] = -1\n",
    "        print(f'{names[index+1]}:')\n",
    "        \n",
    "    # colorize prediction\n",
    "    pred_color = colorEncode(pred, colors).astype(np.uint8)\n",
    "\n",
    "    # aggregate images and save\n",
    "    im_vis = np.concatenate((img, pred_color), axis=1)\n",
    "    display(PIL.Image.fromarray(im_vis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"sky_segmentation-2023-02-13-20-59-24\"\n",
    "MODEL_DIR = \"../artifacts/models/\"\n",
    "model = SkySegmentationModel.load_from_checkpoint(\n",
    "        checkpoint_path=os.path.join(MODEL_DIR, experiment_name, \"last.ckpt\"),\n",
    "        architecture=\"unet\",\n",
    "        encoder_name=\"resnet18\",\n",
    "        learning_rate=1e-4,\n",
    "        in_channels=3,\n",
    "        out_classes=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = smp.encoders.get_preprocessing_params(\"resnet18\")\n",
    "test_transform = A.Compose(\n",
    "        [\n",
    "            A.PadIfNeeded(\n",
    "                pad_height_divisor=32,\n",
    "                pad_width_divisor=32,\n",
    "                min_height=None,\n",
    "                min_width=None,\n",
    "                position=\"top_left\",\n",
    "                border_mode=0,\n",
    "                value=0,\n",
    "                always_apply=False,\n",
    "                p=1.0,\n",
    "            ),\n",
    "            A.Normalize(mean=params[\"mean\"], std=params[\"std\"]),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read splits from disk\n",
    "with open(\"../artifacts/data/metadata/splits.json\", \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "index = 50\n",
    "image_filename = splits[\"train\"][index] + \".jpg\"\n",
    "segmentation_filename = splits[\"train\"][index] + \".png\"\n",
    "\n",
    "path = \"../artifacts/data/ADEChallengeData2016/images/training/\" + image_filename\n",
    "segmentation_path = \"../artifacts/data/ADEChallengeData2016/annotations/training/\" + segmentation_filename\n",
    "\n",
    "pil_image = PIL.Image.open(path).convert('RGB')\n",
    "segmentation_mask = np.array(PIL.Image.open(segmentation_path))\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../artifacts/data/ADEChallengeData2016/images/training/ADE_train_00000983.jpg\"\n",
    "segmentation_path = \"../artifacts/data/ADEChallengeData2016/annotations/training/ADE_train_00000983.png\"\n",
    "segmentation_mask = PIL.Image.open(segmentation_path)\n",
    "pil_image = PIL.Image.open(path).convert('RGB')\n",
    "original_image_size = pil_image.size\n",
    "img_original = np.array(pil_image)\n",
    "img_data = test_transform(image=img_original)[\"image\"].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original.shape, img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_mask = model(img_data)\n",
    "logits_mask = logits_mask[:, :, : original_image_size[1], : original_image_size[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = torch.sigmoid(logits_mask)\n",
    "pred_mask = (pred_mask > 0.5).float()\n",
    "\n",
    "pred_mask = pred_mask.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask.shape, img_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 1 mask to 2 \n",
    "pred_mask = np.where(pred_mask == 1, 2, pred_mask)\n",
    "# convert 0 mask to -1\n",
    "pred_mask = np.where(pred_mask == 0, -1, pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_result(img_original, pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_segmentation_mask = np.array(segmentation_mask)\n",
    "np_segmentation_mask = np.where(\n",
    "            np_segmentation_mask==3,\n",
    "            2*np.ones_like(np_segmentation_mask),\n",
    "            -1*np.zeros_like(np_segmentation_mask),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualize_result(img_original, np_segmentation_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ba359a8d62fc104a5a0f6aee4674e069b699e14f9b76a845a4c68e164258003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
